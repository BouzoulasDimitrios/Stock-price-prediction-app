{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/.local/lib/python3.10/site-packages/fix_yahoo_finance/__init__.py:0: DeprecationWarning: \n",
      "\n",
      "*** `fix_yahoo_finance` was renamed to `yfinance`. ***\n",
      "Please install and use `yfinance` directly using `pip install yfinance -U`\n",
      "\n",
      "More information: https://github.com/ranaroussi/yfinance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yfinance\n",
    "import fix_yahoo_finance as yf\n",
    "import torch\n",
    "from torch import nn \n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "import math, time\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data using yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(ticker, start_date, end_date):\n",
    "    '''\n",
    "        takes in stock name: \"AAPL\"\n",
    "        starting date : '2010-01-01'\n",
    "        ending date : '2015-01-01'\n",
    "    '''\n",
    "    data = yf.download(ticker, start_date, end_date) \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(stock, lookback: int):\n",
    "    '''\n",
    "        \n",
    "    '''\n",
    "    data_raw = stock.to_numpy()\n",
    "    data = []\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "\n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    y_test = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "            \n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach())) #2\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, inputed_scaler):\n",
    "    data = data[['Close']]\n",
    "    scaler = inputed_scaler\n",
    "    data['Close'] = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 16\n",
    "num_layers = 3\n",
    "output_dim = 1\n",
    "saved_model_path = \"predict_stock_price_using_lstm_in_pytorch\"\n",
    "\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load stock tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     MMM\n",
       "1     AOS\n",
       "2     ABT\n",
       "3    ABBV\n",
       "4    ABMD\n",
       "Name: Symbol, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_data = pd.read_csv('constituents_csv.csv')\n",
    "tickers = snp_data['Symbol']\n",
    "tickers.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch  4 MSE:  0.0001908777339849621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53249/2233421617.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Close'] = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n"
     ]
    }
   ],
   "source": [
    "list_of_Scores = []\n",
    "failed = 0\n",
    "num_epochs = 5\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "for t in range(num_epochs):\n",
    "\n",
    "    for i,ticker in enumerate(tickers):\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        try:\n",
    "            data = yf.download(r, '2010-01-r1', '2023-02-02') \n",
    "            if(data['Close'].empty):\n",
    "                raise ValueError('Error')    \n",
    "            data = preprocess_data(data, scaler)\n",
    "\n",
    "        except: # in case the r is not foundrthe stock is skipped\n",
    "            print(\"didnt find anything \\n\\n\")\n",
    "            continue\n",
    "    \n",
    "        hist = np.zeros(num_epochs)\n",
    "        lstm = []\n",
    "        lookback = 21\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_data(data, lookback)\n",
    "\n",
    "        y_train_pred = model(x_train)\n",
    "\n",
    "        loss = criterion(y_train_pred, y_train)\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "        hist[t] = loss.item()\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # testing part\n",
    "        y_test_pred = model(x_test)\n",
    "\n",
    "        y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "        y_train = scaler.inverse_transform(y_train.detach().numpy())\n",
    "        testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.4341],\n",
       "         [-0.0786],\n",
       "         [ 0.0391],\n",
       "         [ 0.4482],\n",
       "         [ 0.4537],\n",
       "         [ 0.3636],\n",
       "         [ 0.0818],\n",
       "         [-0.4042],\n",
       "         [-0.4087],\n",
       "         [-0.0378],\n",
       "         [-0.1639],\n",
       "         [ 0.3221],\n",
       "         [ 0.0529],\n",
       "         [-0.4152],\n",
       "         [ 0.2148],\n",
       "         [-0.3201],\n",
       "         [ 0.7079],\n",
       "         [-0.2633],\n",
       "         [ 0.0650],\n",
       "         [ 0.3662],\n",
       "         [ 0.1797],\n",
       "         [ 0.5411],\n",
       "         [-0.0758],\n",
       "         [-0.1590],\n",
       "         [-0.0701],\n",
       "         [-0.1155],\n",
       "         [ 0.0424],\n",
       "         [ 0.1348],\n",
       "         [ 0.2604],\n",
       "         [-0.2676],\n",
       "         [ 0.1159],\n",
       "         [-0.2882],\n",
       "         [-0.3739],\n",
       "         [-0.0382],\n",
       "         [ 0.5268],\n",
       "         [-0.3181],\n",
       "         [ 0.6131],\n",
       "         [ 0.4973],\n",
       "         [-0.2911],\n",
       "         [-0.5464],\n",
       "         [-0.5739],\n",
       "         [ 0.4347],\n",
       "         [-0.5882],\n",
       "         [-0.4750],\n",
       "         [ 0.3217],\n",
       "         [ 0.5119],\n",
       "         [ 0.0558],\n",
       "         [ 0.3174],\n",
       "         [ 0.8171],\n",
       "         [-0.2187],\n",
       "         [ 0.0879],\n",
       "         [ 0.3081],\n",
       "         [ 0.3711],\n",
       "         [ 0.4963],\n",
       "         [-0.0554],\n",
       "         [-0.1587],\n",
       "         [-0.4045],\n",
       "         [-0.1413],\n",
       "         [ 0.0914],\n",
       "         [-0.0067],\n",
       "         [ 0.0715],\n",
       "         [-0.4118],\n",
       "         [ 0.0552],\n",
       "         [-0.3648]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1433, -0.2814,  0.0747,  ...,  0.3116, -0.1248,  0.1363],\n",
       "         [ 0.3257, -0.2528, -0.1058,  ...,  0.1519,  0.0027, -0.1373],\n",
       "         [-0.1567, -0.0114,  0.0330,  ..., -0.0059, -0.2450, -0.2035],\n",
       "         ...,\n",
       "         [-0.1093,  0.3324,  0.0383,  ..., -0.2181, -0.1546, -0.0115],\n",
       "         [-0.0988,  0.0769,  0.2373,  ...,  0.0045,  0.2000,  0.1373],\n",
       "         [-0.1846,  0.2205, -0.3531,  ..., -0.1913, -0.0162,  0.0490]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2948, -0.3294,  0.0979, -0.0044, -0.1149,  0.0148, -0.1042,  0.3907,\n",
       "          0.2404, -0.1175,  0.0320,  0.1305, -0.3234,  0.3049,  0.0511,  0.0051,\n",
       "         -0.0037,  0.0450,  0.1664, -0.0012, -0.0602,  0.2215, -0.8199, -0.2519,\n",
       "         -0.2571, -0.1954,  0.0852, -0.2363, -0.2558, -0.1701, -0.3066, -0.0019,\n",
       "          0.0804, -0.0762,  0.2343,  0.0883,  0.0534, -0.1364, -0.0092, -0.0158,\n",
       "          0.1215, -0.0594, -0.1485, -0.1390,  0.0098, -0.1914, -0.1728,  0.2517,\n",
       "         -0.2997, -0.2696,  0.1779, -0.1791, -0.0437,  0.1908, -0.3448,  0.0050,\n",
       "          0.0236,  0.2991,  0.3762,  0.1395, -0.0701,  0.0323,  0.0858, -0.1482],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0927, -0.3373,  0.0309, -0.1618,  0.2816,  0.2230, -0.1650,  0.0152,\n",
       "          0.2960,  0.1194,  0.0440,  0.1281,  0.0518, -0.0316, -0.2038, -0.1782,\n",
       "         -0.2334, -0.3848, -0.1954,  0.0249, -0.0879, -0.0540, -0.7516, -0.2288,\n",
       "         -0.2063, -0.2620, -0.0649, -0.3535, -0.1617, -0.1228, -0.0390, -0.0183,\n",
       "         -0.0600,  0.1114, -0.1218,  0.0444,  0.1259,  0.1897, -0.0291, -0.0153,\n",
       "         -0.1926,  0.0400,  0.1022,  0.0372,  0.0484,  0.1788,  0.1781, -0.1534,\n",
       "         -0.2700, -0.0361,  0.2050, -0.3357,  0.0934,  0.1405, -0.0403,  0.4408,\n",
       "          0.2996,  0.0813,  0.0845, -0.2091, -0.3191,  0.2924, -0.0328,  0.1792],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4211, -0.0755, -0.2338,  ..., -0.3203,  0.1896, -0.1645],\n",
       "         [-0.0561, -0.3037,  0.5093,  ...,  0.6772,  0.2984,  0.1491],\n",
       "         [ 0.1655, -0.2685, -0.0889,  ..., -0.1777,  0.1646, -0.0917],\n",
       "         ...,\n",
       "         [-0.2883,  0.1261,  0.0445,  ..., -0.1759, -0.0277, -0.3831],\n",
       "         [-0.5098,  0.3776,  0.2831,  ...,  0.2214,  0.3067, -0.2059],\n",
       "         [-0.1972,  0.2968,  0.3088,  ...,  0.0536, -0.0857, -0.1466]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0149, -0.4964,  0.0961,  ..., -0.0197,  0.3152, -0.1133],\n",
       "         [ 0.0141, -0.1816,  0.1440,  ..., -0.0448, -0.2539,  0.3314],\n",
       "         [ 0.0454,  0.3653,  0.0705,  ...,  0.0372, -0.0636, -0.1196],\n",
       "         ...,\n",
       "         [ 0.1002, -0.3789,  0.0112,  ...,  0.0333,  0.3573, -0.0548],\n",
       "         [-0.4091,  0.2256,  0.1274,  ...,  0.1072,  0.0862,  0.3398],\n",
       "         [-0.1615, -0.0578,  0.1319,  ...,  0.0660, -0.0914,  0.2214]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 3.3193e-01, -2.6018e-01, -2.2490e-01,  4.7250e-02, -1.7063e-01,\n",
       "          1.5957e-02,  1.8682e-02,  3.0529e-01,  2.0347e-01, -1.0438e-01,\n",
       "          5.2261e-02,  5.0912e-01, -8.4663e-02,  2.0507e-01,  5.6473e-02,\n",
       "         -1.1782e-02, -1.2092e-01, -3.0834e-01, -2.2691e-02, -1.9887e-01,\n",
       "         -4.2396e-01,  7.8575e-02, -1.6889e-01, -1.8501e-01, -2.5459e-01,\n",
       "         -6.6321e-02,  1.6409e-01, -6.9131e-02,  1.0056e-01, -8.3432e-02,\n",
       "         -3.9025e-01,  2.1358e-01,  7.2511e-02, -9.8922e-02, -6.5221e-02,\n",
       "          1.5404e-01,  7.4987e-03,  2.8576e-02, -1.1741e-01, -6.5201e-02,\n",
       "         -1.5893e-02,  2.7465e-02, -8.1800e-02,  2.4848e-02, -9.0219e-02,\n",
       "         -1.8097e-01, -5.0772e-02,  1.7248e-01,  1.8672e-01, -1.0024e-01,\n",
       "         -2.9449e-01,  2.9832e-01,  1.8405e-01,  3.7816e-02,  2.5877e-01,\n",
       "          5.1292e-01, -2.6670e-01, -2.7379e-01, -1.1705e-01,  8.1908e-02,\n",
       "         -2.9864e-01,  1.0883e-01, -2.3509e-04,  2.2878e-01],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0070, -0.1862, -0.3564,  0.0395, -0.0733, -0.1911,  0.1364,  0.4833,\n",
       "         -0.1048, -0.3114, -0.0920,  0.1509, -0.0359,  0.0877,  0.0917, -0.0592,\n",
       "         -0.1224, -0.3501, -0.2776, -0.1932, -0.3894, -0.2272, -0.0021,  0.0193,\n",
       "         -0.1844, -0.4401, -0.1956, -0.3553, -0.2263, -0.2411,  0.0481,  0.0245,\n",
       "         -0.0289,  0.0460,  0.0478, -0.1920,  0.1270, -0.1376,  0.1825,  0.1005,\n",
       "         -0.0038, -0.0463,  0.2077,  0.0832, -0.1154,  0.1745,  0.1075, -0.1258,\n",
       "          0.3947, -0.2388,  0.0170, -0.0089, -0.0591,  0.0045,  0.1203,  0.4949,\n",
       "         -0.2286,  0.0510, -0.0270,  0.0418, -0.2066,  0.1631, -0.1415,  0.3745],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1078, -0.2886, -0.0115,  ..., -0.1370, -0.1986,  0.2069],\n",
       "         [-0.0614, -0.4316, -0.0726,  ...,  0.1404,  0.2799,  0.1782],\n",
       "         [-0.0221,  0.0107,  0.1706,  ..., -0.1942,  0.0788,  0.0194],\n",
       "         ...,\n",
       "         [ 0.0831,  0.5347,  0.0066,  ..., -0.0084, -0.3991, -0.4676],\n",
       "         [-0.1420,  0.0033,  0.1841,  ..., -0.1487,  0.0127, -0.0170],\n",
       "         [ 0.2454,  0.0096,  0.1540,  ...,  0.1501,  0.0186, -0.0929]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1901, -0.1254,  0.0889,  ..., -0.1596, -0.0313,  0.0467],\n",
       "         [-0.0788, -0.1832, -0.0861,  ...,  0.0762,  0.1103,  0.0746],\n",
       "         [ 0.1637, -0.2286,  0.1242,  ..., -0.1900, -0.1829,  0.0421],\n",
       "         ...,\n",
       "         [ 0.0198, -0.0584,  0.0101,  ...,  0.1452, -0.1924,  0.0637],\n",
       "         [-0.1467, -0.0278,  0.1022,  ..., -0.2480,  0.0049, -0.1249],\n",
       "         [ 0.1766,  0.1470, -0.0600,  ...,  0.2920,  0.1274, -0.0780]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0555,  0.0850,  0.0951, -0.0938,  0.3280,  0.6269,  0.1688, -0.1410,\n",
       "         -0.1484,  0.3519,  0.1562,  0.0158,  0.2362, -0.0332,  0.2628, -0.4856,\n",
       "          0.1626, -0.2872,  0.0329, -0.2922,  0.1284, -0.1768, -0.2735, -0.4758,\n",
       "         -0.1529,  0.1492,  0.1729, -0.2553,  0.1372, -0.1338, -0.1233, -0.2214,\n",
       "          0.1116, -0.0113,  0.2164, -0.2166, -0.1506,  0.1673, -0.1953, -0.0399,\n",
       "          0.1121,  0.0183, -0.0352, -0.1783, -0.0098, -0.1559,  0.0623, -0.1168,\n",
       "         -0.1373,  0.1691,  0.2416,  0.0330,  0.1762,  0.1942,  0.2275, -0.1158,\n",
       "          0.0511, -0.1392,  0.4256,  0.3812,  0.0831,  0.1973,  0.2263, -0.3798],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0665,  0.1190,  0.1828, -0.1523,  0.3188,  0.4856,  0.1190, -0.0922,\n",
       "         -0.2822,  0.1887,  0.3102,  0.2211,  0.0228,  0.1718, -0.0564, -0.2416,\n",
       "         -0.2705,  0.0281, -0.1765,  0.0438, -0.0636, -0.1329,  0.0357, -0.0201,\n",
       "         -0.1780,  0.1108,  0.2313, -0.3208, -0.3163, -0.1229, -0.0019, -0.4163,\n",
       "         -0.0801,  0.0947, -0.1595,  0.0581,  0.1278, -0.1172,  0.1293,  0.0637,\n",
       "         -0.0467, -0.0677,  0.0292,  0.1505,  0.0290, -0.1557, -0.0794,  0.1273,\n",
       "         -0.2367,  0.2480, -0.1031, -0.2050,  0.0696,  0.2215,  0.1048, -0.3128,\n",
       "         -0.1156,  0.3200,  0.3483, -0.0162, -0.0197,  0.0895,  0.1743, -0.0322],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2144, -0.1767, -0.2657,  0.2475,  0.2727, -0.2523, -0.4416, -0.1110,\n",
       "          -0.0779,  0.2173,  0.3730,  0.2535, -0.2262,  0.2675, -0.2042,  0.0293]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0592], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model = \"predict_stock_price_weights\"\n",
    "torch.save(model.state_dict(), save_model)\n",
    "list(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
